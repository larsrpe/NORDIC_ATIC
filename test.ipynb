{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,2).requires_grad_(True) \n",
    "m = torch.rand(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.cdist(x,m)\n",
    "print(dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5339,  0.8456],\n",
      "        [ 0.0000,  0.0000]])\n",
      "tensor([[-0.5339,  0.8456],\n",
      "        [ 0.7553,  0.6554]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    dist[i,0].backward(retain_graph=True)\n",
    "    print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densities import GMM\n",
    "x = torch.rand(2,2).requires_grad_(True).float()\n",
    "m = torch.rand(1,2).float()\n",
    "w = torch.tensor([1]).float()\n",
    "gmm = GMM(m,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "y = gmm.eval_batch(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    y[i].backward(retain_graph=True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.2973, -6.2973],\n",
      "        [-6.8855, -6.8855]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((x-m)/x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kde import GaussianKDE as KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0066, 1.6359], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kde = KDE(1/5)\n",
    "X = torch.rand(10,2).float()\n",
    "R = torch.rand(2,2).float().requires_grad_(True)\n",
    "f_hat = kde.estimate_batch(R,X)\n",
    "print(f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1172,  0.1835],\n",
      "        [ 0.0000,  0.0000]])\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [-1.1560, -4.5386]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    f_hat[i].backward(retain_graph=True)\n",
    "    print(R.grad)\n",
    "    R.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dot = torch.randn(1,2)\n",
    "f_d = torch.randn(10,1)\n",
    "\n",
    "# multiply each element of m_dot with each element of f_d\n",
    "feed_forward = f_d@m_dot\n",
    "feed_forward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7206)\n",
      "tensor([[2.0343, 1.3475]])\n"
     ]
    }
   ],
   "source": [
    "m0 = torch.randn((1,2))\n",
    "m1 = torch.randn((1,2))\n",
    "t= torch.tensor(0.5,requires_grad=True)\n",
    "h = t/2\n",
    "m = ((1-h)*m0 + t*m1)\n",
    "m[0,0].backward(retain_graph=True)\n",
    "print(t.grad)\n",
    "print(m1-m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "k = 5\n",
    "x = torch.randn(B,2)\n",
    "w = torch.randn(k)\n",
    "e = torch.randn(B,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = e*w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        d = e[i,j]*w[j]-y[i,j]\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdot = torch.rand(k,2)\n",
    "v = y@mdot\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "\n",
    "x = torch.randn(N,3, requires_grad=True)\n",
    "y = x.pow(2).sum(1)\n",
    "I_N = torch.eye(N)\n",
    "# Sequential approach\n",
    "jacobian= torch.autograd.grad(y, x,torch.ones(N))[0]\n",
    "print(jacobian.shape) \n",
    "print(jacobian-2*x)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1])\n"
     ]
    }
   ],
   "source": [
    "B = 15\n",
    "x = torch.rand(B,2)\n",
    "w = torch.rand(N)\n",
    "e = torch.rand(B,N)\n",
    "m0 = torch.rand(N,1)\n",
    "m1  = torch.rand(N,1)\n",
    "t = torch.tensor(0.5,requires_grad=True)\n",
    "m = (1-t)*m0 + t*m1\n",
    "ff = torch.zeros(B,1)\n",
    "for i in range(B):\n",
    "    ff[i]=torch.autograd.grad(m[:,0],t,e[i],retain_graph=True)[0]\n",
    "print(ff.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.densities import GMM\n",
    "B = 300\n",
    "N = 5353\n",
    "x = torch.rand(B,2).requires_grad_(True)\n",
    "m0 = torch.rand(N,2)\n",
    "m1  = torch.rand(N,2)\n",
    "t = torch.tensor(0.5,requires_grad=True)\n",
    "m = (1-t)*m0 + t*m1\n",
    "w = torch.rand(N)\n",
    "w/=w.sum()\n",
    "gmm = GMM(m.detach(),w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n",
      "torch.Size([300, 5000])\n"
     ]
    }
   ],
   "source": [
    "f_d = gmm.eval_batch(x)\n",
    "comps = gmm.get_components_batch(x)\n",
    "print(f_d.shape)\n",
    "print(comps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ff = torch.zeros_like(x)\n",
    "for i in range(B):\n",
    "    for j in range(2):\n",
    "        ff[i,j]=torch.autograd.grad(m[:,j],t,comps[i],retain_graph=True)[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dot = torch.zeros_like(m)\n",
    "for i in range(m.shape[0]):\n",
    "    for j in range(m.shape[1]):\n",
    "        m[i,j].backward(retain_graph=True)\n",
    "        m_dot[i,j] = t.grad\n",
    "        t.grad.zero_()\n",
    "feed_foward = comps@m_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.5879e-09, -6.9849e-10],\n",
      "        [ 1.8626e-09,  6.9849e-10],\n",
      "        [-3.7253e-09, -1.6298e-09],\n",
      "        [ 0.0000e+00, -3.4925e-09],\n",
      "        [-3.7253e-09, -2.7940e-09],\n",
      "        [ 5.5879e-09, -4.6566e-10],\n",
      "        [ 1.8626e-09, -3.7253e-09],\n",
      "        [ 5.5879e-09,  3.7253e-09],\n",
      "        [ 6.5193e-09, -1.8626e-09],\n",
      "        [-5.5879e-09, -3.2596e-09]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.gmminterpolator import GMMInterpolator\n",
    "gmminter = GMMInterpolator.walking_man(0,20,(64,64))\n",
    "gmminter.load_coeff('resolution64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 2])\n",
      "torch.Size([4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(gmminter.ms[0].shape)\n",
    "print(gmminter.PIs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = gmminter.PIs[0]\n",
    "m0 = gmminter.ms[0]\n",
    "m1 = gmminter.ms[1]\n",
    "idx = (p0.flatten()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "repeat interleave\n",
      "tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print('repeat:')\n",
    "print(a.repeat(2,1))\n",
    "print('repeat interleave')\n",
    "print(a.repeat_interleave(2,0))\n",
    "c = torch.tensor([[1,2],[3,4]])\n",
    "print(c)\n",
    "print(c.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5353, 2])\n",
      "torch.Size([5353, 2])\n"
     ]
    }
   ],
   "source": [
    "m0_ext = m0.repeat_interleave(p0.size(0),0)[idx]\n",
    "print(m0_ext.shape)\n",
    "m1_ext = m1.repeat(p0.size(1),1)[idx]\n",
    "print(m1_ext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m m \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mt)\u001b[39m*\u001b[39mm0_ext \u001b[39m+\u001b[39m t\u001b[39m*\u001b[39mm1_ext\n\u001b[1;32m      7\u001b[0m gmm \u001b[39m=\u001b[39m GMM(m\u001b[39m.\u001b[39mdetach(),p0\u001b[39m.\u001b[39mflatten()[idx])\n\u001b[0;32m----> 8\u001b[0m f_d \u001b[39m=\u001b[39m gmm\u001b[39m.\u001b[39;49meval_batch(x)\n\u001b[1;32m      9\u001b[0m comps \u001b[39m=\u001b[39m gmm\u001b[39m.\u001b[39mget_components_batch(x)\n",
      "File \u001b[0;32m~/Documents/NTNU/V23/ATIC/NORDIC_ATIC/src/densities.py:32\u001b[0m, in \u001b[0;36mGMM.eval_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m square_dist \u001b[39m=\u001b[39m dmat\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     31\u001b[0m exp \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mmath\u001b[39m.\u001b[39mpi\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar)\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar)\u001b[39m*\u001b[39msquare_dist)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m exp\u001b[39m@self\u001b[39;49m\u001b[39m.\u001b[39;49mweights\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.densities import GMM\n",
    "B = 300\n",
    "x = torch.rand(B,2)\n",
    "t = torch.tensor(0.5,requires_grad=True)\n",
    "m = (1-t)*m0_ext + t*m1_ext\n",
    "gmm = GMM(m.detach(),p0.flatten()[idx])\n",
    "f_d = gmm.eval_batch(x)\n",
    "comps = gmm.get_components_batch(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aticETH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
